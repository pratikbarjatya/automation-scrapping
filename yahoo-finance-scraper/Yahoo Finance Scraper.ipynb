{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dm3P3dtD-MGP"
      },
      "source": [
        "---\n",
        "\n",
        "# **Importing of Libraries**\n",
        "\n",
        "- In this section, we have imported all the libraries that we will used to scrap yahoo finance historical data.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "YpekTEEC9q94"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import datetime\n",
        "import pandas as pd\n",
        "from datetime import timezone\n",
        "from datetime import datetime as dt\n",
        "from selenium import webdriver\n",
        "from bs4 import BeautifulSoup\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.common.by import By"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "nxoP34fc9q-C",
        "outputId": "4235f8d6-e7c1-435b-ac81-f471fa2dd1a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data Shape: (161, 2)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Stock Name</th>\n",
              "      <th>SYMBOL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ACC LIMITED</td>\n",
              "      <td>ACC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ADANI PORT &amp; SEZ LTD</td>\n",
              "      <td>ADANIPORTS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ADANI ENTERPRISES LIMITED</td>\n",
              "      <td>ADANIENT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ADANI POWER LTD</td>\n",
              "      <td>ADANIPOWER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AMBUJA CEMENTS LTD</td>\n",
              "      <td>AMBUJACEM</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Stock Name      SYMBOL\n",
              "0                ACC LIMITED         ACC\n",
              "1       ADANI PORT & SEZ LTD  ADANIPORTS\n",
              "2  ADANI ENTERPRISES LIMITED    ADANIENT\n",
              "3            ADANI POWER LTD  ADANIPOWER\n",
              "4         AMBUJA CEMENTS LTD   AMBUJACEM"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.read_csv('List of Stocks case study.csv')\n",
        "print('Data Shape:', data.shape)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# **Yahoo Finance Scraper**\n",
        "\n",
        "- In this section, we will scrap the items as highlighted in the red box in the following image.\n",
        "\n",
        "![img](./images/yahoo-finance-webpage.PNG?raw=true)\n",
        "\n",
        "- We will use the following code to extract records of last N days of the given ticker in CSV file.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPMeBiNg9q-H",
        "outputId": "9223b8d9-29f4-4694-bc01-22cf537ce79f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data for ACC scraped successfully!\n",
            "Data for ADANIPORTS.NS scraped successfully!\n",
            "Data for ADANIENT.NS scraped successfully!\n",
            "Data for ADANIPOWER.NS scraped successfully!\n",
            "Data for AMBUJACEM.NS scraped successfully!\n",
            "Data for APOLLOHOSP.NS scraped successfully!\n",
            "Data for ARVIND.NS scraped successfully!\n",
            "Data for ASIANPAINT.NS scraped successfully!\n",
            "Data for AUROPHARMA.NS scraped successfully!\n",
            "Data for BAJFINANCE.NS scraped successfully!\n",
            "Data for BALKRISIND.NS scraped successfully!\n",
            "Data for BANKBARODA.NS scraped successfully!\n",
            "Data for BANKINDIA.NS scraped successfully!\n",
            "Data for BERGEPAINT.NS scraped successfully!\n",
            "Data for BHEL.NS scraped successfully!\n",
            "Data for BAJAJFINSV.NS scraped successfully!\n",
            "Data for NVAX scraped successfully!\n",
            "Data for NVAX scraped successfully!\n",
            "Data for NVAX scraped successfully!\n",
            "Data for CHOLAFIN.NS scraped successfully!\n",
            "Data for NVAX scraped successfully!\n",
            "Data for DIVISLAB.NS scraped successfully!\n",
            "Data for NVAX scraped successfully!\n",
            "Data for ENGINERSIN.NS scraped successfully!\n",
            "Data for NVAX scraped successfully!\n",
            "Data for ESCORTS.NS scraped successfully!\n",
            "Data for NVAX scraped successfully!\n",
            "Data for NVAX scraped successfully!\n",
            "Data for NVAX scraped successfully!\n",
            "Data for NVAX scraped successfully!\n",
            "Data for NVAX scraped successfully!\n",
            "Data for BSOFT.NS scraped successfully!\n",
            "Data for HDFCBANK.NS scraped successfully!\n",
            "Error occured while scraping data for HDFCBANK.NS\n",
            "Data for NVAX scraped successfully!\n",
            "Data for NVAX scraped successfully!\n",
            "Data for NVAX scraped successfully!\n",
            "Data for NVAX scraped successfully!\n",
            "Data for IDFCFIRSTB.NS scraped successfully!\n",
            "Data for CASTROLIND.NS scraped successfully!\n",
            "Data for NVAX scraped successfully!\n",
            "Data for INDUSINDBK.NS scraped successfully!\n",
            "Data for INFY scraped successfully!\n",
            "Data for NVAX scraped successfully!\n",
            "Error occured while scraping data for 0P0000NNE6.BO\n",
            "Data for NVAX scraped successfully!\n",
            "Data for JINDALSTEL.NS scraped successfully!\n",
            "Data for NVAX scraped successfully!\n",
            "Data for JSWSTEEL.NS scraped successfully!\n",
            "Data for JUBLFOOD.NS scraped successfully!\n",
            "Data for JUSTDIAL.NS scraped successfully!\n",
            "Data for NVAX scraped successfully!\n",
            "Data for EXIDEIND.NS scraped successfully!\n",
            "Error occured while scraping data for EXIDEIND.NS\n",
            "Data for LUPIN.NS scraped successfully!\n",
            "Error occured while scraping data for LUPIN.NS\n",
            "Data for NVAX scraped successfully!\n",
            "Data for NVAX scraped successfully!\n",
            "Data for NVAX scraped successfully!\n",
            "Error occured while scraping data for NVAX\n",
            "Data for NVAX scraped successfully!\n",
            "Data for MRF.NS scraped successfully!\n",
            "Data for MUTHOOTFIN.NS scraped successfully!\n",
            "Data for NATIONALUM.NS scraped successfully!\n",
            "Data for NCC.NS scraped successfully!\n",
            "Data for NVAX scraped successfully!\n",
            "Data for NESTLEIND.NS scraped successfully!\n",
            "Data for NVAX scraped successfully!\n",
            "Data for NVAX scraped successfully!\n",
            "Data for PAGEIND.NS scraped successfully!\n",
            "Error occured while scraping data for PAGEIND.NS\n",
            "Data for NVAX scraped successfully!\n",
            "Data for NVAX scraped successfully!\n",
            "Data for NVAX scraped successfully!\n",
            "Data for RAMCOCEM.NS scraped successfully!\n",
            "Data for NVAX scraped successfully!\n",
            "Data for NVAX scraped successfully!\n",
            "Data for NVAX scraped successfully!\n",
            "Data for RELIANCE.NS scraped successfully!\n",
            "Data for NVAX scraped successfully!\n",
            "Data for SIEGY scraped successfully!\n",
            "Data for NVAX scraped successfully!\n",
            "Data for SRTRANSFIN.NS scraped successfully!\n",
            "Data for STAR scraped successfully!\n",
            "Data for NVAX scraped successfully!\n",
            "Data for NVAX scraped successfully!\n",
            "Data for NVAX scraped successfully!\n",
            "Data for NVAX scraped successfully!\n",
            "Data for NVAX scraped successfully!\n",
            "Data for MINDTREE.NS scraped successfully!\n",
            "Data for TORNTPOWER.NS scraped successfully!\n",
            "Data for UBL.NS scraped successfully!\n",
            "Data for UJJIVANSFB.NS scraped successfully!\n",
            "Data for NVAX scraped successfully!\n",
            "Data for NVAX scraped successfully!\n",
            "Data for NVAX scraped successfully!\n",
            "Data for VOLTAS.NS scraped successfully!\n",
            "Data for WIT scraped successfully!\n",
            "Data for NVAX scraped successfully!\n",
            "Data for NVAX scraped successfully!\n",
            "Data for NVAX scraped successfully!\n",
            "Data for RELINFRA.NS scraped successfully!\n",
            "Data for APOLLOTYRE.NS scraped successfully!\n",
            "Data for AXISBANK.NS scraped successfully!\n",
            "Data for TMDI scraped successfully!\n",
            "Data for ASHOKLEY.NS scraped successfully!\n",
            "Data for NVAX scraped successfully!\n",
            "Data for BATAINDIA.NS scraped successfully!\n",
            "Error occured while scraping data for BATAINDIA.NS\n",
            "Data for BHARATFORG.NS scraped successfully!\n",
            "Data for NVAX scraped successfully!\n",
            "Data for BPCL.NS scraped successfully!\n",
            "Data for BRITANNIA.NS scraped successfully!\n",
            "Data for NVAX scraped successfully!\n",
            "Data for NVAX scraped successfully!\n",
            "Data for NVAX scraped successfully!\n",
            "Data for NVAX scraped successfully!\n",
            "Data for DISHTV.NS scraped successfully!\n",
            "Data for NVAX scraped successfully!\n",
            "Data for GMRINFRA.NS scraped successfully!\n",
            "Data for NVAX scraped successfully!\n",
            "Data for NVAX scraped successfully!\n",
            "Data for NVAX scraped successfully!\n",
            "Data for NVAX scraped successfully!\n",
            "Data for NVAX scraped successfully!\n",
            "Data for NVAX scraped successfully!\n",
            "Data for IBULHSGFIN.NS scraped successfully!\n",
            "Data for NVAX scraped successfully!\n",
            "Data for NVAX scraped successfully!\n",
            "Data for MANAPPURAM.NS scraped successfully!\n",
            "Data for MFSL.NS scraped successfully!\n",
            "Data for NVAX scraped successfully!\n",
            "Data for MARUTI.NS scraped successfully!\n",
            "Data for OFSS.NS scraped successfully!\n",
            "Data for NMDC.NS scraped successfully!\n",
            "Error occured while scraping data for NMDC.NS\n",
            "Data for POWERGRID.NS scraped successfully!\n",
            "Data for RBLBANK.NS scraped successfully!\n",
            "Data for SHREECEM.NS scraped successfully!\n",
            "Data for NVAX scraped successfully!\n",
            "Data for TATASTEEL.NS scraped successfully!\n",
            "Data for TATAELXSI.NS scraped successfully!\n",
            "Data for TORNTPHARM.NS scraped successfully!\n",
            "Data for TVSMOTOR.NS scraped successfully!\n",
            "Data for ULTRACEMCO.NS scraped successfully!\n",
            "Data for ZEEL.NS scraped successfully!\n",
            "Data for NVAX scraped successfully!\n",
            "Data for ICICIBANK.NS scraped successfully!\n",
            "Data for LICHSGFIN.NS scraped successfully!\n",
            "Data for NVAX scraped successfully!\n",
            "Data for BHARTIARTL.NS scraped successfully!\n",
            "Error occured while scraping data for NNDM\n",
            "Error occured while scraping data for NNDM\n",
            "Error occured while scraping data for NNDM\n",
            "Error occured while scraping data for NNDM\n",
            "Error occured while scraping data for NNDM\n",
            "Error occured while scraping data for NNDM\n",
            "Error occured while scraping data for NNDM\n",
            "Error occured while scraping data for NNDM\n",
            "Error occured while scraping data for NNDM\n",
            "Error occured while scraping data for NNDM\n",
            "CPU times: user 29.8 s, sys: 1.6 s, total: 31.4 s\n",
            "Wall time: 47min 18s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# Initialize webdriver with options\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "\n",
        "driver = webdriver.Chrome(\"chromedriver\", options=chrome_options)\n",
        "driver.get('https://finance.yahoo.com/')\n",
        "\n",
        "for tiker in data['SYMBOL']:\n",
        "    try:\n",
        "        driver.find_element(by=By.XPATH, value='//*[@id=\"yfin-usr-qry\"]').send_keys(Keys.CONTROL + \"a\")\n",
        "        driver.find_element(by=By.XPATH, value='//*[@id=\"yfin-usr-qry\"]').send_keys(tiker)\n",
        "        driver.find_element(by=By.XPATH, value='//*[@id=\"yfin-usr-qry\"]').send_keys(Keys.RETURN)\n",
        "        time.sleep(3)\n",
        "        # driver.find_element_by_xpath('//*[@id=\"quote-nav\"]/ul/li[5]/a').click()\n",
        "        driver.find_element(by=By.XPATH, value='//a[contains(@href, \"history?p\")]').click()\n",
        "\n",
        "        time.sleep(3)\n",
        "        ticker_name = driver.current_url.split('=')[1]\n",
        "\n",
        "        # Estimate the timestamp of current day and the previous N days\n",
        "        days = 30\n",
        "        records = list()\n",
        "\n",
        "        current_date = dt.now().date()\n",
        "        current_date = dt.strptime(str(current_date), \"%Y-%m-%d\")\n",
        "        current_timestamp = int(current_date.replace(tzinfo=timezone.utc).timestamp())\n",
        "\n",
        "        previous_date = current_date - datetime.timedelta(days)\n",
        "        previous_timestamp = int(previous_date.replace(tzinfo=timezone.utc).timestamp())\n",
        "        \n",
        "        time.sleep(3)\n",
        "        driver.find_element(by=By.XPATH, value='//*[@id=\"Col1-1-HistoricalDataTable-Proxy\"]/section/div[1]/div[1]/button').click()\n",
        "        time.sleep(3)\n",
        "\n",
        "        driver.get('https://finance.yahoo.com/quote/'+ ticker_name + '/history?period1=' + str(previous_timestamp) + '&period2=' + str(current_timestamp) + '&interval=1d&filter=history&frequency=1d&includeAdjustedClose=true')\n",
        "\n",
        "        time.sleep(3)\n",
        "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "        results = soup.find('table', attrs={'data-test': 'historical-prices'}).find('tbody').find_all('tr')\n",
        "\n",
        "        for result in results:\n",
        "            row_list = list()\n",
        "            row = result.findAll('span')\n",
        "            for item in row:\n",
        "                row_list.append(item.text)\n",
        "            records.append(row_list)\n",
        "\n",
        "        columns = ['Date', 'Open', 'High', 'Low', 'Close', 'AdjustedClose', 'Volume']\n",
        "\n",
        "        data = pd.DataFrame(data=records, columns=columns)\n",
        "        data.to_csv(path_or_buf='saves/'+ticker_name+'_stock_data.csv', index=False)\n",
        "        print('Data for', ticker_name, 'scraped successfully!')\n",
        "    except:\n",
        "        print('Error occured while scraping data for', ticker_name)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Stock_scraper.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "23263b619eede791ee76531faea33d0ac3cfe2e28e54d2f570a826170ba9147e"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
